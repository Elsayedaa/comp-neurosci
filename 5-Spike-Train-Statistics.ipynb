{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Lesson 5: Spikes and spike train statistics\n",
    "\n",
    "As we've seen from previous examples, much of the data generated by the brain consists of spikes (i.e., action potentials). We all know that neurons spike when they are excited, but what does this mean quantitatively?\n",
    "\n",
    "In this lesson, we'll dive into a fairly simple but foundational model that attempts to quantify spiking as the function of an underlying **rate**.\n",
    "\n",
    "Our goals are to:\n",
    "\n",
    "- understand homogeneous and inhomogeneous Poisson process models\n",
    "- be able to estimate the latent rate variable in Poisson models\n",
    "\n",
    "Follow along in the notebook during the lecture, and then work on the cells marked **Q** with help from your instructor. Submit the completed notebook to Collab.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Readings\n",
    "\n",
    "Before coming to class, you should have finished reading Chapter 1 in Dayan and Abbott.\n",
    "\n",
    "For a more in-depth treatment, consult the following papers:\n",
    "\n",
    "- Nawrot M, et al. Single-trial estimation of neuronal firing rates: From single-neuron spike trains to population activity. J Neurosci Methods. [doi:10.1016/S0165-0270(99)00127-2](https://doi.org/10.1016/S0165-0270(99)00127-2)\n",
    "- Shinomoto S. Estimating the Firing Rate. In: Analysis of Parallel Spike Trains. [doi:10.1007/978-1-4419-5675-0_2](https://doi.org/10.1007/978-1-4419-5675-0_2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### More point process math\n",
    "\n",
    "Recall that a point process is an (ordered) sequence of event times:\n",
    "\n",
    "$$X = \\{t_0, t_1, \\ldots, t_{N-1}\\}$$\n",
    "\n",
    "We can represent this as a function by making each spike a [Dirac delta function](https://en.wikipedia.org/wiki/Dirac_delta_function):\n",
    "\n",
    "$$\\rho(t) = \\sum_{i=0}^{N-1} \\delta(t - t_i)$$\n",
    "\n",
    "![spike_train](images/l5_spike_train.png \"spike train delta function\")\n",
    "\n",
    "Because the area under each delta function is 1, this allows us to count spikes or calculate any continuous function of a spike train through integration.\n",
    "\n",
    "For example, the **rate** is defined as the number of spikes $N$ that occurred in some interval divided by the duration of the interval, $T$:\n",
    "\n",
    "$$R = \\frac{N}{T} = \\frac{1}{T} \\int_{0}^{T} d\\tau\\; \\rho(\\tau)$$\n",
    "\n",
    "![spike_train_rate](images/l5_rate_integral.png \"spike train rate integral\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Spiking as a random variable\n",
    "\n",
    "Neural responses are **stochastic**. Even under \"identical\" conditions, spike trains will vary from trial to trial.\n",
    "\n",
    "In other words, the response $\\rho(t)$ is a **random variable**. The probability of observing a particular response is given by a **distribution**, $p(\\rho(t))$.\n",
    "\n",
    "We can also represent the stimulus $\\vec{s}(t)$ as a random variable with a distribution $p(\\vec{s}(t))$, even if it's under experimental control."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Review of probability\n",
    "\n",
    "Leaving out the notation indicating that both $\\rho$ and $\\vec{s}$ are functions of time, the following distributions are of interest:\n",
    "\n",
    "The joint distribution $p(\\rho, \\vec{s})$ is the probability of $\\rho$ and $\\vec{s}$ occurring together. This is likely to be a very small number because the space of $\\vec{s}$ and $\\rho$ are potentially quite large.\n",
    "\n",
    "Thus, we are often more interested in the conditional probability $p(\\rho|\\vec{s})$, which is the probability of observing $\\rho$ when $\\vec{s}$ is presented.\n",
    "\n",
    "The marginal probability $p(\\rho)$ indicates the probability of observing $\\rho$ irrespective of which stimulus was presented.\n",
    "\n",
    "There are two mathematical identities that allow us to convert between these distributions. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### Conditional Probability\n",
    "\n",
    "$$p(\\rho,\\vec{s}) = p(\\rho|\\vec{s})p(\\vec{s}) = p(\\vec{s}|\\rho)p(\\rho)$$\n",
    "\n",
    "If $p(\\rho|\\vec{s}) = p(\\rho)$, then $\\rho$ and $\\vec{s}$ are **independent**. Independence means $p(\\rho)$ is the same regardless of what $\\vec{s}$ is. This means that for independent variables, the joint distribution is simply the product of the marginal distributions.\n",
    "\n",
    "$$p(\\rho,\\vec{s}) = p(\\rho)p(\\vec{s})$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### Marginal Probability\n",
    "\n",
    "We can convert a joint probability distribution to a marginal probability distribution by summing (integrating) the probabilities of one of the variables.\n",
    "\n",
    "$$p(\\rho) = \\int d\\vec{s}\\; p(\\rho, \\vec{s}) = \\int d\\vec{s}\\; p(\\rho|\\vec{s}) p(\\vec{s})$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Spike-train statistics\n",
    "\n",
    "Let's apply these concepts to spike trains:\n",
    "\n",
    "The probability of of a sequence of $N$ spikes $X = \\{t_0,\\ldots,t_{N-1}\\}$ is the joint probability density of all the individual spikes: \n",
    "\n",
    "$$p(t_0, t_1, \\ldots, t_{N-1})$$\n",
    "\n",
    "If the spikes are independent, then this joint distribution is simply the product of the distributions for each spike:\n",
    "\n",
    "$$p(t_0, \\ldots, t_{N-1}) = \\prod_{i=0}^{N-1}p(t_i)$$\n",
    "\n",
    "When each spike is independent of every other spike, we have a **Poisson process**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Homogeneous Poisson Processes\n",
    "\n",
    "If $t_i$ is independent of all the other spikes, what does it depend on?\n",
    "\n",
    "In the simplest case, $p(t_i)$ depends only on the **rate** of spiking, $R$.\n",
    "\n",
    "If the rate is constant, the Poisson process is **homogeneous**. In this case, in an interval $(t_i, t_i + \\Delta)$, we would expect to observe $\\lambda = R\\Delta$ events. The distribution of the number of events we actually observe, $n$, is given by the Poisson distribution:\n",
    "\n",
    "$$p(n|\\lambda) = \\frac{\\lambda^n}{n!}\\exp(-\\lambda)$$\n",
    "\n",
    "The parameter $\\lambda$ is often called the **intensity** of the process."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Let's explore some properties of the Poisson distribution in Python. Here's a graph of the distribution from wikipedia:\n",
    "\n",
    "![poisson_distro](https://upload.wikimedia.org/wikipedia/commons/1/16/Poisson_pmf.svg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# load matplotlib inline mode\n",
    "%matplotlib inline\n",
    "\n",
    "# import some useful libraries\n",
    "import numpy as np                # numerical analysis linear algebra\n",
    "import matplotlib.pyplot as plt   # plotting\n",
    "\n",
    "# import the poisson distro\n",
    "from tools import dists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# first, let's define our *support*: the values over which we want to evalute p(n):\n",
    "supp = np.arange(0, 20)\n",
    "\n",
    "# next, we *instantiate* the distribution object with our parameter lambda\n",
    "dist = dists.poisson(1.0)\n",
    "\n",
    "# you can get the probability of any value in the distribution with .pmf. Note that we have to use\n",
    "# pmf (probability mass function) rather than pdf.\n",
    "print(\"p(5|lambda=1) =\", dist.pmf(5))\n",
    "\n",
    "# we can also evaluate the distribution over a vector of numbers\n",
    "prob = dist.pmf(supp)\n",
    "\n",
    "# and plot the distribution with plt.plot\n",
    "plt.plot(supp, prob, lw=3);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "**Q**: In the cell below, try to evaluate the `prob` distribution for negative or non-integral numbers. Given the definition of the Poisson distribution, why is this the case?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "**Q** Recall that $\\lambda = R\\Delta$. If $R = 1$ Hz and you steadily reduce $\\Delta$ from 1.0 s to 1.0 microseconds, what is the probability of observing one spike in that interval? Write a *for loop* to evaluate and plot this. Does the result make sense? What is the probability of a spike occurring at some *exact* time?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Delta = [1e0, 5e-1, 1e-1, 5e-2, 1e-2, 5e-3, 1e-3, 5e-4, 1e-4, 5e-5, 1e-5, 5e-6, 1e-6]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "In addition to plotting the probability distribution, Python can generate random samples (i.e, **draw**) from the Poisson distribution, too."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# note: 'lambda' is a reserved symbol in python\n",
    "lam = 1.0\n",
    "dist = dists.poisson(lam)\n",
    "# rvs stands for random value(s)\n",
    "n = dist.rvs(1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "**Q** In the cell below, calculate the sample mean and standard deviation for n, then try with a few other values of lambda."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"The sample mean when lambda=\", lam, \"is\", np.mean(n))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Mean: $\\mu =$\n",
    "- Standard deviation: $\\sigma =$\n",
    "- Fano factor $\\sigma^2/\\mu =$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### From Poisson distribution to Poisson process\n",
    "\n",
    "How can we generate a series of spike times from the Poisson distribution? The trick is to divide your response interval up into a set of smaller intervals (or **bins**) such that the probability of observing more than one spike in a single bin is very small, then draw from $p(n|\\lambda)$ for each bin."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "T     = 100     # s\n",
    "rate  = 4.0     # Hz\n",
    "Delta = 0.001   # s\n",
    "dist   = dists.poisson(rate * Delta)\n",
    "spikes = dist.rvs(int(T / Delta))\n",
    "bins   = np.arange(0, T, Delta)\n",
    "\n",
    "fig, axes = plt.subplots(nrows=1, ncols=1, figsize=(9, 4))\n",
    "axes.plot(bins, spikes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "The plot of the `spikes` array should only show `0` and `1` values. If it doesn't, what do you need to do?\n",
    "\n",
    "You can think of the `spikes` array as a sort of time series representation of the point process. \n",
    "\n",
    "To get the actual spike times, we need to find the bins where there is a spike and then look up the times in the `bins` array:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spike_i = np.nonzero(spikes)[0]\n",
    "spike_t = bins[spike_i]\n",
    "# here's one way to plot a raster of spike times\n",
    "fig, axes = plt.subplots(nrows=1, ncols=1, figsize=(9, 4))\n",
    "axes.plot(spike_t, np.zeros_like(spike_t), \"|\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### More spike train statistics\n",
    "\n",
    "**Q** Here's a slightly harder question about the properties of Poisson processes. Calculate the interspike *intervals* from `spike_t` (hint: look at the documentation for `np.diff`), then plot a histogram. What function does this look like? Calculate the sample mean and variance. How do these relate to the rate of the process? What is the coefficient of variation of the interspike distribution (CV = $\\mu / \\sigma$)?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Inhomogeneous Poisson Processes\n",
    "\n",
    "It's also possible for the rate of a Poisson process to vary in time; that is, for $\\lambda$ to be a function of $t$.\n",
    "\n",
    "$$p(n|\\lambda(t)) = \\frac{\\lambda(t)^n}{n!}\\exp(-\\lambda(t))$$\n",
    "\n",
    "As before, we need to discretize time and determine the probability that there is a spike in some interval $(t, t + \\Delta)$; the only difference is that some intervals are more likely to have spikes than others.\n",
    "\n",
    "We could simulate an inhomogeneous Poisson process in much the same way as we did above, but we need to vary $\\lambda$ in each bin. There's a somewhat easier method that's based on the Bernoulli distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "T     = 100     # s\n",
    "Delta = 0.001   # s\n",
    "N     = int(T / Delta)\n",
    "bins  = np.arange(0, T, Delta)\n",
    "# rate is now a function of time\n",
    "rate  = np.concatenate([np.linspace(0.0, 4.0, N//2),\n",
    "                        np.linspace(4.0, 0.0, N//2)])\n",
    "\n",
    "# generate N values from a uniform distribution\n",
    "rand = dists.uniform().rvs(N)\n",
    "# compare each value to lambda = rate * Delta\n",
    "lam  = rate * Delta\n",
    "spikes = (rate * Delta) > rand\n",
    "spike_i = np.nonzero(spikes)[0]\n",
    "spike_t = bins[spike_i]\n",
    "# here's one way to plot a raster of spike times\n",
    "fig, axes = plt.subplots(nrows=1, ncols=1, figsize=(9, 4))\n",
    "axes.plot(bins, rate)\n",
    "axes.plot(spike_t, np.zeros_like(spike_t), \"k|\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q** Calculate the mean, variance, and CV of the interspike intervals for this spike train. Is the relationship with the rate the same as you discovered for the homogeneous process?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Estimating spike rates\n",
    "\n",
    "Let's think about how we can estimate $\\lambda$ for Poisson processes.\n",
    "\n",
    "If we assume that the process is homogeneous over each trial, then we have a simple observational model where the number of spikes is a random sample from the Poisson distribution.\n",
    "\n",
    "$$p(y_i|\\lambda) = \\frac{\\lambda^n}{n!}\\exp(-\\lambda)$$\n",
    "\n",
    "Given a set of trials, we can estimate $\\lambda$ using a simple maximum-likelihood procedure like we explored in the last lesson.\n",
    "\n",
    "If we're presenting different stimuli on each trial, we can model $\\lambda$ as depending on some function of which stimulus was present. If the function is the exponential of a linear sum, then we have a generalized linear model.\n",
    "\n",
    "$$\\log(\\lambda_i) = \\beta_0 + \\vec{\\beta}\\cdot\\mathbf{X} + T$$\n",
    "\n",
    "More on this later."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "The problem is a lot trickier if the process is inhomogeneous, because now we're trying to estimate a continuous function of time, $\\lambda(t)$.\n",
    "\n",
    "In this setting, people usually talk about rate rather than intensity ($\\lambda$), so we'll use $r(t)$ from here on.\n",
    "\n",
    "The issue we confront is that $r(t)$ is a continuous function. We can discretize it into small intervals of $(t, t + \\Delta)$ and count the number of spike in each interval, but as we make $\\Delta$ smaller to get higher temporal resolution, we reach the point at which each bin has either one or zero spikes, which doesn't tell us much about the rate. We can address this problem by averaging across multiple trials. If we use $\\langle \\rangle$ to denote averaging across trials, this looks like:\n",
    "\n",
    "$$r(t) = \\frac{1}{\\Delta} \\int_t^{t+\\Delta} d\\tau\\; \\langle \\rho(t) \\rangle$$\n",
    "\n",
    "You hopefully can see that as $\\Delta$ gets smaller, the number of trials you need to average to get a smooth function gets larger. So part of our problem is to determine what $\\Delta$ should be. More practically, at what time scale do we think the rate is changing?\n",
    "\n",
    "There are a number of different ways of approximating $r(t)$. We'll look at a couple."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Spike time histogram\n",
    "\n",
    "For historical reasons, this is also called a peri-stimulus spike time histogram (PSTH), even when there isn't a stimulus.\n",
    "\n",
    "The simplest way of approximating the rate is to divide the interval up into a fixed number of bins of duration $\\Delta$ and count how many spikes occurred in each bin. The rate is simply the number of spikes divided by $\\Delta$.\n",
    "\n",
    "The main problem with histograms is setting the bin size. Try adjusting the binsize variable and see what gives you the best tradeoff between variability and temporal resolution.\n",
    "\n",
    "There is still active development of new methods for adaptively setting bin sizes in timing histograms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "binsize = 5.0\n",
    "r_est, edges  = np.histogram(spike_t, bins=np.arange(0, T, binsize))\n",
    "plt.plot(bins, rate)\n",
    "plt.step(edges[1:], r_est / binsize)\n",
    "plt.plot(spike_t, np.zeros_like(spike_t), \"k|\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Smoothing\n",
    "\n",
    "Another problem with the PSTH is that the count in each bin can depend very strongly on where the edges of the bins are.\n",
    "\n",
    "One solution to this problem is to use a **sliding window**. The simplest window is simply a square function with a defined width and a total area equal to 1.0.\n",
    "\n",
    "For example, here's a 10 ms window."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "window_size = 2.0\n",
    "w_t = np.arange(-10.0, 10.0, Delta)\n",
    "w = np.zeros_like(w_t)\n",
    "w[(-window_size/2 < w_t) & (w_t <window_size/2)] = 1. / window_size\n",
    "plt.plot(w_t, w)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Convolution\n",
    "\n",
    "We can express the sliding window operation as a sum of the window function for the values of the spike times.\n",
    "\n",
    "$$r(t) \\approx \\sum_{i=0}^{N-1} w(t - t_i)$$\n",
    "\n",
    "This is equivalent to doing an integral over the response function:\n",
    "\n",
    "$$r(t) \\approx \\int_{-\\infty}^{\\infty} d\\tau\\; w(\\tau) \\rho(t - \\tau)$$\n",
    "\n",
    "This integral is also called a linear **convolution** or filter, and we'll be seeing a lot of them.\n",
    "\n",
    "Numpy has a function that can calculate this convolution:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r_est = np.convolve(spikes, w, mode='same')\n",
    "plt.plot(bins, rate)\n",
    "plt.plot(bins, r_est)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "You can use any function as a window as long as it goes to zero outside $\\tau = 0$ and its integral is 1.0.\n",
    "\n",
    "A popular choice is to use a Gaussian, which smooths the function by downweighting points further away from $\\tau = 0$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sigma = 2\n",
    "w = 1 / np.sqrt(2 * np.pi) / sigma * np.exp(-w_t**2 / 2 / sigma**2)\n",
    "plt.plot(w_t, w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r_est = np.convolve(spikes, w, mode='same')\n",
    "plt.plot(bins, rate)\n",
    "plt.plot(bins, r_est)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Putting it together\n",
    "\n",
    "For the rest of the class period, work on the following exercises.\n",
    "\n",
    "#### Exercise 1\n",
    "\n",
    "Consider an inhomogeneous Poisson process with a time-varying intensity specified by:\n",
    "\n",
    "$$\\lambda(t) = 1/4[\\sin(2\\pi\\omega t)  + ]$$\n",
    "\n",
    "Use $\\omega$ = 3 Hz, and a response interval from 0 to 2 s."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q** Plot r(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q** Generate 20 independently simulated spike trains and plot them as rasters. There is code in previous notebooks you can use to make the raster plot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q**. Using a bin size of 10 ms, calculate two PSTHs averaged from 10 independently simulated spike trains, and two PSTHs averaged from 1000 spike trains. How do these PSTHs relate to $\\lambda(t)$? What do you learn by comparing and contrasting these PSTHs?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q** Plot the distribution of spike counts in each bin of the 1000-trial PSTH and calculate the mean, variance, and Fano factor. What is the shape of the distribution?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q** Change the binsize to 150 ms, plot the PSTH, and re-calculate the mean and variance of the spike counts. What effect does this have?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "comp-neurosci",
   "language": "python",
   "name": "comp-neurosci"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "rise": {
   "scroll": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
