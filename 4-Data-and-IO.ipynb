{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# 3B: Data Input/Output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Computational neuroscience often involves a lot of data. In this lesson, you'll learn about:\n",
    "\n",
    "- different kinds of data, how they are stored on disk\n",
    "- how to read data from the disk into your program\n",
    "- how to store data from your program to the disk\n",
    "\n",
    "We'll consider three kinds of data:\n",
    "\n",
    "- [time series](#Time-series-data)\n",
    "- [point processes](#Point-processes)\n",
    "- [structured records](#Structured-records)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Time series data\n",
    "\n",
    "Typically represented as an **array** of measurements: \n",
    "\n",
    "$$\\mathbf{x} = \\{x_0, x_1, \\ldots, x_N\\}$$\n",
    "\n",
    "Can be **multichannel** if more than one measurement taken at a time. Each time point is now a **vector** ($\\vec{x}$):\n",
    "\n",
    "$$\\mathbf{X} = \\{\\vec{x}_0, \\vec{x}_1, \\ldots, \\vec{x}_N\\}$$\n",
    "\n",
    "Multichannel time series are represented as two-dimensional arrays. One dimension correponds to time and the other to the component of the measurement vector.\n",
    "\n",
    "Note that the \"channels\" can be repeated **trials** rather than simultaneous measurements."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Time series in Python\n",
    "\n",
    "We use `numpy` arrays to store single- and multichannel time series in Python. Let's look at an example using some Gaussian white noise.\n",
    "\n",
    "Gaussian noise is drawn from a normal distribution, and it's called white noise because it has equal power at all frequencies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(1)                  # set random seed so we all get the same results\n",
    "x = np.random.randn(1000)          # generate 100 random WN samples\n",
    "\n",
    "plt.plot(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can determine the number of elements in a 1D array using the `len()` function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"The number of points in x is:\", len(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "**Q**: Do you recall from the last exercise how to access subsets of a numpy array? In the code cell below, write an expression to evaluate the mean of the first 100 samples of `x`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Numpy (and Python in general) supports **negative indexing**, which means that negative indices are interpreted as referencing elements from the **end** of the array. The following expression gives us the mean of the last 100 elements."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(x[-100:1000])\n",
    "# you can leave out the second index in the slice if it refers to the end of the array, so this is equivalent:\n",
    "np.mean(x[-100:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Multichannel time series\n",
    "\n",
    "For multichannel data, the array has two dimensions. There is a (weak) convention that the first dimension of the array represents time. That means each column represents a separate channel.\n",
    "\n",
    "Here is an example of a 3-channel array, again using Gaussian white noise. I've added some correlations between the channels to make things interesting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = np.random.multivariate_normal(mean=[0, 0, 0], cov=[[1.0, 0.2, 0.0],[0.2, 1.0, 0.1], [0.0, 0.1, 1.0]], size=1000)\n",
    "plt.plot(y);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice how the plot now has three different-colored traces? Matplotlib assumes that time is the first dimension when you give it an array to plot.\n",
    "\n",
    "The size along each dimension of the array is called its **shape**. You can get the shape (and therefore the dimension of an array) using the `.shape` attribute:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"The shape of y is:\", y.shape)\n",
    "# note that len returns the number of elements along the first dimension\n",
    "print(\"The number of time points in y is:\", len(y))\n",
    "print(\"The total size of y is:\", y.size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "For multichannel data, we need two indices or slices to access values in the array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the first time point in the first channel. Note the comma.\n",
    "y[0, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use `:` to indicate all the values along one dimension. This gives all the values for the first channel\n",
    "plt.plot(y[:, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to get all the channels at a time point:\n",
    "print(\"y_0 =\", y[0, :])\n",
    "# you can leave out the trailing indices\n",
    "print(\"y_0 =\", y[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "**Q**: Calculate and plot the mean of all three channels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Enter code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Input/Output \n",
    "\n",
    "Presumably you'd like to look at more than just randomly generated noise. So how do you get data from a recording into your program?\n",
    "\n",
    "Usually, data are stored long-term on your computer's drive or in the cloud. There are advantage to both approaches, which we'll discuss later. For now, we're going to retrieve some files that I prepared for you to your local machine. Once we do this, we'll see how to load the data from these files.\n",
    "\n",
    "Executing the following cell will run a shell command to retreive some data files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!curl -s 'https://gracula.psyc.virginia.edu/public/courseware/comp_neurosci_data_022719.tgz' | tar zxv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### I/O for Time Series\n",
    "\n",
    "Unfortunately, there is no agreed-upon standard for storing time series data, so you'll have to do some sleuthing.\n",
    "\n",
    "There are three major kinds of storage formats: text, binary, and custom."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Text\n",
    "\n",
    "One way of storing numbers is how you would write them (i.e., as **text**). \n",
    "\n",
    "When reading a text file, the main thing you need to know is how the elements are separated. \n",
    "\n",
    "For single-channel data, usually each number goes on its own line. \n",
    "\n",
    "For multi-channel data, there will be multiple numbers per line, typically separated by white space (tabs and/or spaces) or by commas.\n",
    "\n",
    "When you're storing data in text format, you also need to be mindful of the precision. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### Reading text files\n",
    "\n",
    "One advantage of storing data as text is that it's human-readable. However, this isn't as much of an advantage as you might think. \n",
    "\n",
    "To see an example of an extracellular recording in text format, switch to the main Juptyer tab in your browser, navigate to the `data/io-examples` folder, and click on one of the files that ends in `.txt`\n",
    "\n",
    "Numpy can easily load single- and multi-channel data from text files using the `loadtxt` command:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = np.loadtxt(\"data/io-examples/st11_1_2_A8.txt\")\n",
    "plt.plot(d)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Binary\n",
    "\n",
    "Storing numbers as text is very inefficient. Let's see why."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## text is read into Python first as a string:\n",
    "s = open(\"data/io-examples/st11_1_2_A8.txt\", \"r\").readline().strip()\n",
    "print(\"the number as text:\", s)\n",
    "print(\"size of the text (in bytes):\", len(s))\n",
    "\n",
    "## to use it as a number, python has to parse the text\n",
    "f = float(s)\n",
    "print(\"the number as a float:\", f)\n",
    "print(\"size of a float (in bytes):\", d.dtype.itemsize)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### Reading binary data\n",
    "\n",
    "Not only does text-formatted data take up a lot more space, it also requires additional work for Python to translate into a numerical representation that it can do math on (i.e., floats and ints).\n",
    "\n",
    "This inefficiency becomes a consideration for large datasets. Thus, we often want to store the data on disk in a binary format, i.e., the same format as it would be in memory.\n",
    "\n",
    "A very powerful method for reading and writing binary data is to use a **memory map**. This essentially takes the contents of a binary file and treats it as an array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os   # standard library module used to construct paths\n",
    "\n",
    "d = np.memmap(os.path.join(\"data\", \"io-examples\", \"st11_1_2_A8.dat\"), mode=\"r\", dtype='d')\n",
    "plt.plot(d)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Structured formats\n",
    "\n",
    "Text and raw binary formats both have shortcomings and tradeoffs.\n",
    "\n",
    "A shortcoming they both have in common is that it can be difficult to store metadata.\n",
    "\n",
    "Without metadata, it may be hard to know how to interpret the contents of the file."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Some critical metadata we need for time series include:\n",
    "\n",
    "- sampling rate\n",
    "- dimensions of the array\n",
    "- ordering of the array (i.e., time first or last) and what's in each channel\n",
    "- measurement units\n",
    "\n",
    "**Q**: What other metadata do you think are important for time series data? Write a couple of ideas in the cell below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Structured data formats can be text- or binary-based.\n",
    "\n",
    "Some formats are used widely and are well-documented, like [Javascript Object Notation](http://json.org) or [HDF5](https://support.hdfgroup.org/HDF5/). These formats are likely to have well-supported Python packages for I/O.\n",
    "    \n",
    "Other formats are more obscure or proprietary, like Axon Binary Format (ABF) or [Elan](http://elan.lyon.inserm.fr/). It may be difficult to find Python support to read these files, though the situation is improving thanks to projects like [Neo IO](https://neo.readthedocs.io/)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Point processes\n",
    "\n",
    "Typically represented as an ordered sequence of times in some interval from 0 to $T$:\n",
    "\n",
    "$$\\{0 \\leq t_0 < t_1 < \\ldots < t_N \\leq T\\}$$\n",
    "\n",
    "In contrast to time series, there is not a fixed relationship between the number of events and the duration of the analysis interval."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Point process data in Python\n",
    "\n",
    "Point processes are also typically stored in `numpy` arrays, but the elements of the array are event times, not measurements.\n",
    "\n",
    "Because point processes vary in the number of events, multi-channel point-processes are represented by **lists of arrays**, not by 2D arrays.\n",
    "\n",
    "Let's look at some examples:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tools import pprox\n",
    "resp = pprox.load(\"data\", \"starling\", \"pprox\", \"st11_1_2_1\")\n",
    "resp_A8 = pprox.select_stimulus(resp, \"A8\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The variable `resp_A8` points to a Python **list**. Lists are like arrays, but they can store heterogeneous data types. The syntax for accessing elements and slices is the same.\n",
    "\n",
    "**Q:** Using what you know from previous exercises, complete the following code cell to print out some information about the data: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"The number of trials is:\", ???)\n",
    "print(\"The number of events in trial 0 is:\", ???)\n",
    "print(\"The time of the first event in trial 2 is:\", ???)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## I/O for Point Processes\n",
    "\n",
    "Just as there is no agreed-upon standard for storing time series data, there is also no standard format for point-process data.\n",
    "\n",
    "Because point process data tend to be smaller than time series, text formats are more common than binary.\n",
    "\n",
    "A very simple text format is to put each trial (or channel) on a separate line and separate the events on each line with a space. Take a look at `data/io-examples/st_11_2_1_A8.txt` for an example.\n",
    "\n",
    "The [PySpike](http://mariomulansky.github.io/PySpike/) library has a function for loading data from such files, but we're going to write our own so that we can learn a bit about basic I/O in Python and looping."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a list where we will store our trials\n",
    "trials = []\n",
    "# open the file for reading\n",
    "fp = open(os.path.join(\"data\", \"io-examples\", \"st11_1_2_1_A8.txt\"), mode=\"r\")\n",
    "# loop through the lines of the file with a for statement\n",
    "for line in fp:\n",
    "    # read the line into an array\n",
    "    arr = np.fromstring(line, sep=\" \")\n",
    "    # append the array to our list\n",
    "    trials.append(arr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you learned how to program in Java or C or another low-level programming language, take a moment to appreciate how simple this task is in Python."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Checking our work\n",
    "\n",
    "**Q:** The `trials` list we created in the last code cell should be the same as `resp_A8`. In the cell below, complete **three assert** statements to check that this is true. I've provided you with one to get started. If you complete your task correctly, the cell will not emit any errors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert len(trials) == len(resp_A8), \"The number of trials is not the same\"\n",
    "assert True == False, \"The total number of events is not the same\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Point process metadata\n",
    "\n",
    "As with time series data, it's important to keep track of metadata. Here are some important metadata that need to be associated with point process files:\n",
    "\n",
    "- type of event (e.g., spike, behavioral action, stimulus start/stop)\n",
    "- number of channels\n",
    "- unit scaling (e.g., milliseconds or seconds?)\n",
    "- start time\n",
    "- other experimental variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Structured Records\n",
    "\n",
    "In both point process and time series data, the elements of the arrays have been **homogeneous** (i.e., all the same type). What if that's not the case?\n",
    "\n",
    "The third (and final) kind of data we'll consider today consists of **records**. Each record in turn comprises **fields**, which may have different types.\n",
    "\n",
    "This kind of data is also called **tabular data**. If you're coming from the R world, you might think of this kind of data as a `data.frame`.\n",
    "\n",
    "It's common to encounter structured records when you have independent observations; for example, from different neurons or animals or populations. The fields in each record might include:\n",
    "\n",
    "- a unique identifier for the observation\n",
    "- group identifiers (e.g., cell, animal, population)\n",
    "- independent variables (e.g., sex, treatment, age)\n",
    "- dependent variable(s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Structured records in Python\n",
    "\n",
    "Python used to lag pretty badly behind R for handling this kind of data, but we now have [pandas](http://pandas.pydata.org/), which is beginning to approach `numpy` in popularity and maturity.\n",
    "\n",
    "As with numpy, there is a convention for importing pandas: \n",
    "\n",
    "```python\n",
    "import pandas as pd\n",
    "```\n",
    "\n",
    "For a detailed introduction to pandas, take a look at [Chapter 3](https://jakevdp.github.io/PythonDataScienceHandbook/03.00-introduction-to-pandas.html) of the Python Data Science Handbook.\n",
    "\n",
    "There are two main concepts to understand in using pandas: `Series` and `DataFrames`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "A `Series` is essentially a column of a table. Like a numpy array, all the elements of a series are the same type. Unlike a numpy array, the indices of a `Series` do not have to be sequential integers, but can be any label you like.\n",
    "\n",
    "For example, here's a `Series` that might represent the ages of several subjects:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "ages = pd.Series([391, 442, 183], index=['st11', 'st22', 'st231'])\n",
    "ages"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can access the elements of a `Series` using the standard Python bracket syntax:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ages['st11']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "A `DataFrame` is a collection of `Series`, i.e. a table of columns. Here's how we might represent the ages and sexes of a set of subjects:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sex = pd.Series(['M', 'F', 'M'], index=['st11', 'st22', 'st231'])\n",
    "subjects = pd.DataFrame({'age': ages, 'sex': sex})\n",
    "subjects"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice how we now have a table, which Jupyter renders nicely for us with the row and column indices are indicated in bold.\n",
    "\n",
    "The bracket syntax for `DataFrames` accesses **columns**. It's important to remember that this is different from numpy arrays, where a single index gives you a row."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subjects['age']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "To index by row and column, you have to use the `loc` attribute:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subjects.loc['st11', 'age']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Equivalently, you can use `iloc` and the numerical indices:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subjects.iloc[0, 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## I/O for Structured Records\n",
    "\n",
    "Structured record data is usually stored on disk in text-based formats. This is because human readability is often quite important. There are two very common formats:\n",
    "\n",
    "- In _comma-separated-value_ files, each record is on a separate line, and fields are separated by commas.\n",
    "- In _whitespace-delimited-value_ files, each record is on a separate line, and fields are separated by white space (tabs or spaces)\n",
    "\n",
    "In both kinds of files, it's common that the first line of the file is a header giving the name for each column.\n",
    "\n",
    "Take a look at `data/stimuli/motifs.csv` for an example of a comma-delimited file.\n",
    "\n",
    "One really good reason to use pandas is that it provides some nice I/O functions for these kinds of files. It's trivial to load tabular data into Python:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "motifs = pd.read_csv(os.path.join(\"data\", \"starling\", \"stimuli\", \"motifs.csv\"))\n",
    "motifs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "You can tell pandas that certain columns should be used as indices.\n",
    "\n",
    "This allows you to select a subset of rows using the `loc` syntax. For example, to see all the rows where `song` is equal to `A8`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "motifs = motifs.set_index(['song'])\n",
    "motifs.loc['A8']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Exercise\n",
    "\n",
    "Write code in the cell below to compute the following:\n",
    "\n",
    "- the number of different songs\n",
    "- the number of motifs for each song\n",
    "- the average motif duration in each song"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "rise": {
   "scroll": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
