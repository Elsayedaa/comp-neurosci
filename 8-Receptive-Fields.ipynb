{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Lesson 8: Receptive Fields\n",
    "\n",
    "In Lesson 6, we discussed linear time-invariant systems, which can serve as a simple model of how the rate of a neuron can depend on a time-varying stimulus.\n",
    "\n",
    "This week, we'll look at some empirical findings about how neurons in the visual system respond to simple stimuli, and then consider how to represent these responses using an LTI model.\n",
    "\n",
    "Follow along in the notebook during the lecture. There is no assignment associated with this lesson.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# load matplotlib inline mode\n",
    "%matplotlib inline\n",
    "\n",
    "# import some useful libraries\n",
    "import numpy as np                # numerical analysis linear algebra\n",
    "import matplotlib.pyplot as plt   # plotting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Sensory tuning curves\n",
    "\n",
    "As we saw with the frog visual system, neurons do not respond to every stimulus in the world. Instead, they are **tuned** to specific properties of the stimulus.\n",
    "\n",
    "For example, so-called *simple cells* in the primary visual cortex (V1) respond strongly to moving bars, and are tuned to specific orientations. Each cell has a **tuning curve**, $r(s)$, that shows firing rate as a function of orientation:\n",
    "\n",
    "<img src=\"images/l8_orientation_tuning.png\" alt=\"V1 tuning\" style=\"width: 400px;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Receptive fields\n",
    "\n",
    "In the visual system, one of the most fundamental tuning properties of neurons is the region of space that can excite a neuron. This area is called the **receptive field** (or RF) of the neuron.\n",
    "\n",
    "Because visual space is two-dimensional, a spatial tuning curve has two independent variables, $r(x,y)$, and looks like a surface:\n",
    "\n",
    "<img src=\"images/l8_receptive_field_spatial_only.png\" alt=\"lgn receptive field\" style=\"width: 400px;\"/>\n",
    "\n",
    "The peak in the center of the RF is the region of space where a bright spot of light will cause this neuron in the visual thalamus to fire.\n",
    "\n",
    "Note that the RF can also take on negative values, which indicate regions of space where stimuli suppress responses. The effects of suppressive regions can only be observed if the spontaneous rate of the neuron is high, or if suppressive stimuli are combined with excitatory ones."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Temporal tuning\n",
    "\n",
    "Visual neurons also exhibit temporal tuning. That is, they respond best to stimuli that modulate in time. This means that in fact, visual RFs are three-dimensional functions with two spatial and one temporal dimension, i.e. $r(x,y,t)$. The plot below shows one spatial and one temporal dimension:\n",
    "\n",
    "<img src=\"images/l8_receptive_field_temporal.png\" alt=\"lgn receptive field\" style=\"width: 400px;\"/>\n",
    "\n",
    "You can see that at short lags, the central excitatory field is surrounded by suppressive areas. Later, the situation is reversed, and the central area is suppressive. Cutting a cross-section through time at the center of the RF gives a function that looks a bit like this:\n",
    "\n",
    "<img src=\"images/l8_receptive_field_temporal_only.png\" alt=\"lgn receptive field - time only\" style=\"width: 300px;\"/>\n",
    "\n",
    "What does this mean? One intepretation is that the best stimulus is a small dot of light that turns on and then off after about 75 ms. If the light stays on longer, it will start to suppress the response. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Review of LTI systems\n",
    "\n",
    "The temporal RF in the previous slide should hopefully remind you of the impulse response functions we worked with last week. \n",
    "\n",
    "Recall that an LTI system can be completely characterized by its impulse response function (or kernel), $h(t)$. Given this function, you can predict the response to any arbitrary input $x(t)$ using convolution.\n",
    "\n",
    "You should be able to recognize the convolution operator in its discrete form,\n",
    "\n",
    "$$y(t) \\approx \\sum_i h(t - \\tau_i) x(\\tau_i)$$\n",
    "\n",
    "or continuous form,\n",
    "\n",
    "$$y(t) = \\int_0^\\infty h(\\tau) x(t - \\tau) d\\tau$$\n",
    "\n",
    "and understand that because convolution is commutative, either $h(t)$ or $x(t)$ can be time-shifted.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Receptive fields are linear kernels\n",
    "\n",
    "We can generalize the one-dimensional LTI kernel $h(t)$ to more complex stimuli that have non-temporal dimensions.\n",
    "\n",
    "Visual stimuli are extended in two dimensions and change in time, so the stimulus has three dimensions:\n",
    "\n",
    "<img src=\"images/l8_natural_images.png\" alt=\"natural images\" style=\"width: 500px;\"/>\n",
    "\n",
    "You can think of the stimulus as a three-dimensional function, $s(x, y, t)$, or as a time-varying vector, $\\vec{s}(t)$, where $\\vec{s}$ has components that correspond to each of the pixels in the image.\n",
    "\n",
    "This means that the impulse response function for a visual neuron also has three dimensions: $h(x, y, t)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Only the temporal dimension is convolved; the others are simply multiplied in a dot product. To see why this is, think back to our static neuron model:\n",
    "\n",
    "![linear neuron](images/l6_linear_neuron.png)\n",
    "\n",
    "The response at any instant in time is just a weighted sum or dot product:\n",
    "\n",
    "$$y = \\sum_i w_i x_i = \\vec{w} \\cdot \\vec{x}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Therefore, the equation to predict the response to a multivariate stimulus looks like this:\n",
    "\n",
    "$$r(t) = \\sum_i \\sum_j \\sum_k h(x_i, y_j, \\tau_k) s(x_i, y_j, t - \\tau_k)$$\n",
    "\n",
    "Note that because the sums are commutative, this is equivalent to convolving each pixel of the RF with the matching pixel in the stimulus and then summing all the convolutions up together.\n",
    "\n",
    "\\begin{align}\n",
    "r_{i,j}(t) & = \\sum_k h(x_i, y_j, \\tau_k) s(x_i, y_j, t - \\tau_k) \\\\\n",
    "r(t) & = \\sum_i \\sum_j r_{i,j}(t)\n",
    "\\end{align}\n",
    "\n",
    "Keep this in mind when you try to implement in Python. `np.convolve` expects univariate arrays, and other convolution packages may try to convolve along multiple dimensions, which is not what you want."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Static nonlinearity\n",
    "\n",
    "Neurons can't have negative firing rates, and most have a maximum.\n",
    "\n",
    "However, the linear predictions of a kernel are theoretically unbounded.\n",
    "\n",
    "One solution is to pass the linear estimate through an arbitrary function that transforms to a real firing rate. The nonlinearity is **static** because it only applies to each instant in time.\n",
    "\n",
    "So if $L(t) = \\int_0^\\infty h(\\tau) x(t - \\tau) d\\tau$ and $F(\\cdot)$ is a univariate nonlinear function, then\n",
    "\n",
    "$$\\hat{r}(t) = r_0 + F(L(t))$$\n",
    "\n",
    "The nonlinearity can be determined empirically by comparing $L(t)$ to $r(t)$, or it can be parameterized using a number of convenient forms.\n",
    "\n",
    "<img src=\"images/l8_nonlinearity.png\" alt=\"static nonlinearities\" style=\"width: 400px;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear-Nonlinear cascade models\n",
    "\n",
    "This introduces the concept of cascade models, which can be conceptualized as a series of steps where one step takes the output of another step as its input. This can be used to make a complete model that goes all the way from stimulus to spiking response.\n",
    "\n",
    "<img src=\"images/l8_lnp.png\" alt=\"lnp model\" style=\"width: 600px;\"/>\n",
    "\n",
    "Because the cascade model shown above generates spikes through an inhomogeneous Poisson process, it's called a Linear-Nonlinear-Poisson (LNP) model. LNP models are conceptually simple and serve as starting points for many analyses."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Example\n",
    "\n",
    "Let's look at an RF with one spatial and one temporal dimension."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filts = np.load('data/filters.npz')\n",
    "k1 = filts['wb2'] * 25\n",
    "plt.imshow(k1, cmap='jet')\n",
    "plt.xlabel(\"tau (ms)\")\n",
    "plt.ylabel(\"x (px)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "We're going to simulate the response to some low-frequency Gaussian noise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import ndimage\n",
    "nx, nt = k1.shape\n",
    "nsamples = nt * 100\n",
    "np.random.seed(1)\n",
    "stim_raw = np.random.randn(nx, nsamples)\n",
    "stim = ndimage.gaussian_filter(stim_raw, sigma=(10, 50))\n",
    "stim[:,:500] = 0\n",
    "plt.imshow(stim, cmap=\"jet\", aspect='auto')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Now let's do the convolution:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convolve each pixel (row) separately\n",
    "convrows = [np.convolve(k1[i], stim[i]) for i in range(nx)]\n",
    "# sum across rows\n",
    "conv = np.row_stack(convrows).sum(0)\n",
    "\n",
    "fig, axes = plt.subplots(nrows=2, ncols=1, sharex=True, figsize=(9, 4))\n",
    "axes[0].imshow(stim, cmap=\"jet\", aspect='auto')\n",
    "axes[1].plot(conv[:nsamples])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compare the result of the convolution to the stimulus and the RF. Is it what you would expect?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "We now convert the convolution to an estimated rate by passing it through a nonlinear function. We'll use `exp`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r_est = np.exp(conv[:nsamples])\n",
    "plt.plot(r_est)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "And then generate spikes using our standard Bernoulli trick:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lmb = r_est * 0.001\n",
    "n_trials = 10\n",
    "for i in range(n_trials):\n",
    "    runif = np.random.uniform(size=nsamples)\n",
    "    spikes = (lmb > runif).nonzero()[0]\n",
    "    plt.vlines(spikes, i - 0.4, i + 0.4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Estimating RFs\n",
    "\n",
    "As Chapter 2 in Dayan and Abbott discusses in more detail, receptive fields can predict many of the tuning properties of visual neurons. This suggests two key conclusions:\n",
    "\n",
    "1. Visual neurons (up to a point) are pretty linear.\n",
    "2. Linear models have a lot of explanatory power.\n",
    "\n",
    "As a consequence, we often want to try to estimate the linear RF of sensory neurons. Even if the neuron isn't totally linear, it's a good place to start. But how do we infer the kernel in a system where we can't stimulate with a delta function?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Reverse correlation\n",
    "\n",
    "One very simple approach is to average the stimuli that preceded each spike, like so:\n",
    "\n",
    "<img src=\"images/l8_revcor_1d.png\" alt=\"1d reverse correlation\" style=\"width: 400px;\"/>\n",
    "\n",
    "This is called the **spike-triggered average** (STA) or the **reverse correlation**. The latter term is a bit of a historical artifact, because in fact it's simply the cross-correlation of the stimulus and the response."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "The STA is easily generalized to multivariate stimuli:\n",
    "\n",
    "<img src=\"images/l8_revcor_2d.png\" alt=\"2D reverse correlation\" style=\"width: 300px;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Stimulus-triggered ensemble\n",
    "\n",
    "One way of conceptualizing this is by thinking of the set of stimuli presented to the neuron as occupying some high-dimensional space. (*Dimensions* here is the number of pixels, not the number of dimensions in the image)\n",
    "\n",
    "<img src=\"images/l8_stensemble.png\" alt=\"spike-triggered ensemble\" style=\"width: 450px;\"/>\n",
    "\n",
    "The STA is simply the centroid of the ensemble of stimuli that triggered a spike:\n",
    "\n",
    "<img src=\"images/l8_sta_ensemble.png\" alt=\"spike-triggered average\" style=\"width: 450px;\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Stimulus correlations\n",
    "\n",
    "The spike-triggered average only recovers the kernel of an LTI system if there are no correlations in the stimulus. \n",
    "\n",
    "To see why this is, think about how the 1D average would be affected if the stimulus had a lot of low-frequency power, so that the values at any instant in time were correlated with the values around it.\n",
    "\n",
    "Or think about how the average would be affected if the ensemble of black points in the previous slide were not spherical.\n",
    "\n",
    "The practical problem this presents is that many neurons don't respond well to uncorrelated Gaussian noise."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Kernel estimation as linear regression\n",
    "\n",
    "The solution to the foregoing problem is to correct for the correlations in the stimulus.\n",
    "\n",
    "It can be helpful to recast the problem as one of linear regression. Remember the expansion of convolution:\n",
    "\n",
    "$$r(t) = h_0 + h_1 s(t) + h_2 s(t-1) + h_3 s(t-2) + \\cdots$$ \n",
    "\n",
    "We've added a constant offset $h_0$ and then represented the kernel with subscripts starting with 1.\n",
    "\n",
    "We can rewrite the sum as a dot product,\n",
    "\n",
    "$$r(t) = \\vec{s}(t) \\cdot \\vec{h}$$\n",
    "\n",
    "where $\\vec{s}(t)$ refers to the **time-lagged** stimulus. That is $\\vec{s}(t) = \\{s(t), s(t - 1), \\ldots\\}$.\n",
    "\n",
    "Our data consist of a series of observations made for different values of $\\vec{s}$. Some of the variance in these observations is explained by variation in the stimulus; the rest is random noise. Letting $r_i$ be the rate at time $t_i$,\n",
    "\n",
    "$$r_i = \\vec{s}_i \\cdot \\vec{h} + \\varepsilon_i$$\n",
    "\n",
    "We can use matrix notation by stacking all the observations in a vector:\n",
    "\n",
    "$$\\vec{r} = \\mathbf{S} \\vec{h} + \\vec{\\varepsilon}$$\n",
    "\n",
    "In each row, the matrix $\\mathbf{S}$ contains the stimulus at the current time and at a set of previous lags. This is a special form called the [Toeplitz matrix](https://en.wikipedia.org/wiki/Toeplitz_matrix)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Given this model, our goal is to estimate $\\vec{h}$. That is, to find values that maximize the amount of variance explained by the stimulus and minimize the amount of random error ($\\vec{\\varepsilon}$).\n",
    "\n",
    "A standard approach is to try to minimize the sum of the squares of the error. This is called **ordinary least squares** (OLS).\n",
    "\n",
    "Hopefully, you've seen that our model is a pretty vanilla linear model. The OLS solution is well-known:\n",
    "\n",
    "$$\\hat{h} = (\\mathbf{S}^T \\mathbf{S})^{-1} \\mathbf{S}^T \\vec{r} = \\left(\\sum_i \\vec{s}_i \\cdot \\vec{s}_i \\right)^{-1} \\left(\\sum_i \\vec{s}_i r_i \\right)$$\n",
    "\n",
    "- The first term is the autocovariance matrix for the independent variables. \n",
    "- The second term is the covariance between the dependent and independent variables. \n",
    "- Here, these correspond to the **autocorrelation** and the **cross-correlation**\n",
    "\n",
    "If the stimulus is white noise, the correlation between any two instants in time is zero, so $\\mathbf{S}^T\\mathbf{S} = \\sigma^2\\mathbf{I}$ ($\\mathbf{I}$ is the identity matrix and $\\sigma^2$ is the variance of the stimulus).\n",
    "\n",
    "The $^{-1}$ operator stands for **matrix inversion**. This is what \"undoes\" the effects of the correlations in the stimulus. Matrix inversion is computationally expensive and numerically hairy. There are some tricks for dealing with the latter, but for now let's return to our empirical discussion of V1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## \"Simple\" cells\n",
    "\n",
    "In contrast to the center-surround RFs seen in the visual thalamus, many neurons in the primary visual cortex have more complex, elongated RFs.\n",
    "\n",
    "<img src=\"images/l8_simple_rf.png\" alt=\"V1 simple cell RF\" style=\"width: 300px;\"/>\n",
    "\n",
    "This elongation confers **orientation tuning** on these neurons, as illustrated by this simple diagram:\n",
    "\n",
    "<img src=\"images/l8_simple_orientation.png\" alt=\"V1 orientation tuning\" style=\"width: 500px;\"/>\n",
    "\n",
    "Like thalamic neurons, simple cells usually have a temporal profile that inverts over time, which makes the neurons prefer *moving* bars.\n",
    "\n",
    "<img src=\"images/l8_simple_temporal.png\" alt=\"V1 spectrotemporal\" style=\"width: 450px;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Complex cells\n",
    "\n",
    "V1 also contains a number of \"complex\" cells. Like simple cells, these neurons often have strong orientation tuning, but unlike simple cells, their receptive fields do not have clear \"on\" and \"off\" subregions.\n",
    "\n",
    "Hubel and Wiesel theorized that the tuning properties of simple and complex neurons arise from convergence:\n",
    "\n",
    "<img src=\"images/l8_hubel_wiesel.png\" alt=\"Hubel and Wiesel model\" style=\"width: 450px;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## The energy model\n",
    "\n",
    "One model for complex cells is an extension of the simple LNP model in which the nonlinearity combines inputs from multiple LTI filters:\n",
    "\n",
    "<img src=\"images/l8_energy_model.png\" alt=\"LNP energy model\" style=\"width: 400px;\"/>\n",
    "\n",
    "That is,\n",
    "\n",
    "\\begin{align}\n",
    "L_i(t) & = \\sum_j k_i(\\tau_j) s(t - \\tau_j) \\\\\n",
    "r(t) & = r_0 + G(L_1(t), L_2(t), L_3(t), \\ldots)\n",
    "\\end{align}\n",
    "\n",
    "In the energy model, $G$ is simply the sum of the squared outputs of the filters."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Spike-triggered covariance\n",
    "\n",
    "In a purely linear time-invariant model, the sum of more than one filter can be described by a single filter, and it's not possible to recover the component filters.\n",
    "\n",
    "This means that STA or linear regression on complex cells usually just gives you noise.\n",
    "\n",
    "However, there is still structure in the spike-triggered ensemble:\n",
    "\n",
    "<img src=\"images/l8_ste_variance_schwartz.png\" alt=\"spike-triggered ensemble variance\" style=\"width: 500px;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Finding the important dimensions\n",
    "\n",
    "What we need to do is to find the dimensions along which the variance of the STE is greater or less than expected. Just as the STA is a vector in the stimulus space that corresponds to a linear filter, the vectors with unexpected variance also correspond to filters.\n",
    "\n",
    "One method for recovering the dimensions is to use principal components analysis to find the eigenvectors of the STE covariance matrix. Dimensions that have larger or smaller variance than expected are the excitatory and suppressive filters of the cell.\n",
    "\n",
    "<img src=\"images/l8_stc_pca.png\" alt=\"STC PCA\" style=\"width: 300px;\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Estimating the nonlinearity\n",
    "\n",
    "The nonlinearity can be found empirically using Bayes' rule:\n",
    "\n",
    "$$p(\\mathrm{spike}|L_i) = \\frac{p(L_i|\\mathrm{spike})}{p(L_i)}$$\n",
    "\n",
    "<img src=\"images/l8_simple_complex_nonlin.png\" style=\"width: 400px;\"/>\n",
    "\n",
    "As predicted by the energy model, the nonlinearities for complex neurons often have a roughly parabolic shape."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "comp-neurosci",
   "language": "python",
   "name": "comp-neurosci"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "rise": {
   "scroll": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
